{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naughty-superintendent",
   "metadata": {},
   "source": [
    "# Python Lab Week 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c786b8f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5736d3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/zod/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/zod/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/zod/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/zod/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172efcb",
   "metadata": {},
   "source": [
    "## b) Reading in some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hawaiian-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A comfortably plump dog happened to run into a elephant. The elephant asked the dog where he had\n",
      "been finding enough food to get so big and fat. 'It is a man,' said the dog, 'who gives me\n",
      "all this food to eat.' The elephant then asked him, 'And what about that bare spot there on\n",
      "your neck?' The dog replied, 'My skin has been rubbed bare by the iron collar which my\n",
      "master forged and placed upon my neck.' The elephant then jeered at the dog and said, 'Keep\n",
      "your luxury to yourself then! I don't want anything to do with it, if my neck will have to\n",
      "chafe against a chain of iron!'\n",
      "\n",
      "A comfortably plump dog happened to run into a elephant. The elephant asked the dog where he had\n",
      "been finding enough food to get so big and fat. 'It is a man,' said the dog, 'who gives me\n",
      "all this food to eat.' The elephant then asked him, 'And what about that bare spot there on\n",
      "your neck?' The dog replied, 'My skin has been rubbed bare by the iron collar which my\n",
      "master forged and placed upon my neck.' The elephant then jeered at the dog and said, 'Keep\n",
      "your luxury to yourself then! I don't want anything to do with it, if my neck will have to\n",
      "chafe against a chain of iron!'\n"
     ]
    }
   ],
   "source": [
    "with open(r'Lab5text.txt', \"r\") as f:\n",
    "    data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-gauge",
   "metadata": {},
   "source": [
    "## c) Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aerial-calibration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'comfortably', 'plump', 'dog', 'happened', 'to', 'run', 'into', 'a', 'elephant', '.', 'The', 'elephant', 'asked', 'the', 'dog', 'where', 'he', 'had', 'been', 'finding', 'enough', 'food', 'to', 'get', 'so', 'big', 'and', 'fat', '.', \"'It\", 'is', 'a', 'man', ',', \"'\", 'said', 'the', 'dog', ',', \"'who\", 'gives', 'me', 'all', 'this', 'food', 'to', 'eat', '.', \"'\", 'The', 'elephant', 'then', 'asked', 'him', ',', \"'And\", 'what', 'about', 'that', 'bare', 'spot', 'there', 'on', 'your', 'neck', '?', \"'\", 'The', 'dog', 'replied', ',', \"'My\", 'skin', 'has', 'been', 'rubbed', 'bare', 'by', 'the', 'iron', 'collar', 'which', 'my', 'master', 'forged', 'and', 'placed', 'upon', 'my', 'neck', '.', \"'\", 'The', 'elephant', 'then', 'jeered', 'at', 'the', 'dog', 'and', 'said', ',', \"'Keep\", 'your', 'luxury', 'to', 'yourself', 'then', '!', 'I', 'do', \"n't\", 'want', 'anything', 'to', 'do', 'with', 'it', ',', 'if', 'my', 'neck', 'will', 'have', 'to', 'chafe', 'against', 'a', 'chain', 'of', 'iron', '!', \"'\", 'A', 'comfortably', 'plump', 'dog', 'happened', 'to', 'run', 'into', 'a', 'elephant', '.', 'The', 'elephant', 'asked', 'the', 'dog', 'where', 'he', 'had', 'been', 'finding', 'enough', 'food', 'to', 'get', 'so', 'big', 'and', 'fat', '.', \"'It\", 'is', 'a', 'man', ',', \"'\", 'said', 'the', 'dog', ',', \"'who\", 'gives', 'me', 'all', 'this', 'food', 'to', 'eat', '.', \"'\", 'The', 'elephant', 'then', 'asked', 'him', ',', \"'And\", 'what', 'about', 'that', 'bare', 'spot', 'there', 'on', 'your', 'neck', '?', \"'\", 'The', 'dog', 'replied', ',', \"'My\", 'skin', 'has', 'been', 'rubbed', 'bare', 'by', 'the', 'iron', 'collar', 'which', 'my', 'master', 'forged', 'and', 'placed', 'upon', 'my', 'neck', '.', \"'\", 'The', 'elephant', 'then', 'jeered', 'at', 'the', 'dog', 'and', 'said', ',', \"'Keep\", 'your', 'luxury', 'to', 'yourself', 'then', '!', 'I', 'do', \"n't\", 'want', 'anything', 'to', 'do', 'with', 'it', ',', 'if', 'my', 'neck', 'will', 'have', 'to', 'chafe', 'against', 'a', 'chain', 'of', 'iron', '!', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(data)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0195cb",
   "metadata": {},
   "source": [
    "## d) Words with >4 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f15705b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comfortably', 'plump', 'happened', 'into', 'elephant', 'elephant', 'asked', 'where', 'been', 'finding', 'enough', 'food', 'said', \"'who\", 'gives', 'this', 'food', 'elephant', 'then', 'asked', \"'And\", 'what', 'about', 'that', 'bare', 'spot', 'there', 'your', 'neck', 'replied', 'skin', 'been', 'rubbed', 'bare', 'iron', 'collar', 'which', 'master', 'forged', 'placed', 'upon', 'neck', 'elephant', 'then', 'jeered', 'said', \"'Keep\", 'your', 'luxury', 'yourself', 'then', 'want', 'anything', 'with', 'neck', 'will', 'have', 'chafe', 'against', 'chain', 'iron', 'comfortably', 'plump', 'happened', 'into', 'elephant', 'elephant', 'asked', 'where', 'been', 'finding', 'enough', 'food', 'said', \"'who\", 'gives', 'this', 'food', 'elephant', 'then', 'asked', \"'And\", 'what', 'about', 'that', 'bare', 'spot', 'there', 'your', 'neck', 'replied', 'skin', 'been', 'rubbed', 'bare', 'iron', 'collar', 'which', 'master', 'forged', 'placed', 'upon', 'neck', 'elephant', 'then', 'jeered', 'said', \"'Keep\", 'your', 'luxury', 'yourself', 'then', 'want', 'anything', 'with', 'neck', 'will', 'have', 'chafe', 'against', 'chain', 'iron']\n"
     ]
    }
   ],
   "source": [
    "four_letters = []\n",
    "for word in tokens:\n",
    "    if len(word) >= 4:\n",
    "        four_letters.append(word)\n",
    "print(four_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40fb3d4",
   "metadata": {},
   "source": [
    "## e) Tag text with part of speech tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "615ff70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT'), ('comfortably', 'RB'), ('plump', 'NN'), ('dog', 'NN'), ('happened', 'VBD'), ('to', 'TO'), ('run', 'VB'), ('into', 'IN'), ('a', 'DT'), ('elephant', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "speech_char = nltk.pos_tag(tokens)\n",
    "print(speech_char[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77745ee",
   "metadata": {},
   "source": [
    "## f) Create a list containing all the nouns in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260494a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "\n",
    "for word, tag in speech_char:\n",
    "    if tag in ['NN', 'NNS']:\n",
    "        nouns.append(word)\n",
    "print(nouns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-weather",
   "metadata": {},
   "source": [
    "## g) Tag all the named entities such as names of people and places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "smooth-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Far/NNP)\n",
      "  far/RB\n",
      "  away/RB\n",
      "  ,/,\n",
      "  behind/IN\n",
      "  the/DT\n",
      "  word/NN\n",
      "  mountains/VBZ\n",
      "  ,/,\n",
      "  far/RB\n",
      "  from/IN\n",
      "  the/DT\n",
      "  countries/NNS\n",
      "  (PERSON Vokalia/NNP)\n",
      "  and/CC\n",
      "  (GPE Consonantia/NNP)\n",
      "  ,/,\n",
      "  there/EX\n",
      "  live/VBP\n",
      "  the/DT\n",
      "  blind/NN\n",
      "  texts/NN\n",
      "  ./.\n",
      "  Separated/VBD\n",
      "  they/PRP\n",
      "  live/VBP\n",
      "  in/IN\n",
      "  (GPE Bookmarksgrove/NNP)\n",
      "  right/NN\n",
      "  at/IN\n",
      "  the/DT\n",
      "  coast/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Semantics/NNP)\n",
      "  ,/,\n",
      "  a/DT\n",
      "  large/JJ\n",
      "  language/NN\n",
      "  ocean/NN\n",
      "  ./.\n",
      "  A/DT\n",
      "  small/JJ\n",
      "  river/NN\n",
      "  named/VBN\n",
      "  (PERSON Duden/NNP)\n",
      "  flows/NNS\n",
      "  by/IN\n",
      "  their/PRP$\n",
      "  place/NN\n",
      "  and/CC\n",
      "  supplies/NNS\n",
      "  it/PRP\n",
      "  with/IN\n",
      "  the/DT\n",
      "  necessary/JJ\n",
      "  regelialia/NN\n",
      "  ./.\n",
      "  It/PRP\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  paradisematic/JJ\n",
      "  country/NN\n",
      "  ,/,\n",
      "  in/IN\n",
      "  which/WDT\n",
      "  roasted/VBD\n",
      "  parts/NNS\n",
      "  of/IN\n",
      "  sentences/NNS\n",
      "  fly/VBP\n",
      "  into/IN\n",
      "  your/PRP$\n",
      "  mouth/NN\n",
      "  ./.\n",
      "  Even/RB\n",
      "  the/DT\n",
      "  all-powerful/JJ\n",
      "  Pointing/NNP\n",
      "  has/VBZ\n",
      "  no/DT\n",
      "  control/NN\n",
      "  about/IN\n",
      "  the/DT\n",
      "  blind/NN\n",
      "  texts/NN\n",
      "  it/PRP\n",
      "  is/VBZ\n",
      "  an/DT\n",
      "  almost/RB\n",
      "  unorthographic/JJ\n",
      "  life/NN\n",
      "  One/CD\n",
      "  day/NN\n",
      "  however/RB\n",
      "  a/DT\n",
      "  small/JJ\n",
      "  line/NN\n",
      "  of/IN\n",
      "  blind/NN\n",
      "  text/NN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  name/NN\n",
      "  of/IN\n",
      "  (PERSON Lorem/NNP Ipsum/NNP)\n",
      "  decided/VBD\n",
      "  to/TO\n",
      "  leave/VB\n",
      "  for/IN\n",
      "  the/DT\n",
      "  far/RB\n",
      "  World/NNP\n",
      "  of/IN\n",
      "  (GPE Grammar/NNP)\n",
      "  ./.\n",
      "  The/DT\n",
      "  Big/NNP\n",
      "  (PERSON Oxmox/NNP)\n",
      "  advised/VBD\n",
      "  her/PRP$\n",
      "  not/RB\n",
      "  to/TO\n",
      "  do/VB\n",
      "  so/RB\n",
      "  ,/,\n",
      "  because/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  thousands/NNS\n",
      "  of/IN\n",
      "  bad/JJ\n",
      "  (ORGANIZATION Commas/NNP)\n",
      "  ,/,\n",
      "  wild/JJ\n",
      "  Question/NN\n",
      "  (PERSON Marks/NNP)\n",
      "  and/CC\n",
      "  devious/JJ\n",
      "  Semikoli/NNP\n",
      "  ,/,\n",
      "  but/CC\n",
      "  the/DT\n",
      "  (ORGANIZATION Little/NNP Blind/NNP Text/NNP)\n",
      "  didn/NN\n",
      "  â€™/NNP\n",
      "  t/NN\n",
      "  listen/NN\n",
      "  ./.\n",
      "  She/PRP\n",
      "  packed/VBD\n",
      "  her/PRP\n",
      "  seven/CD\n",
      "  versalia/NNS\n",
      "  ,/,\n",
      "  put/VBD\n",
      "  her/PRP$\n",
      "  initial/JJ\n",
      "  into/IN\n",
      "  the/DT\n",
      "  belt/NN\n",
      "  and/CC\n",
      "  made/VBD\n",
      "  herself/PRP\n",
      "  on/IN\n",
      "  the/DT\n",
      "  way/NN\n",
      "  ./.\n",
      "  When/WRB\n",
      "  she/PRP\n",
      "  reached/VBD\n",
      "  the/DT\n",
      "  first/JJ\n",
      "  hills/NNS\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION Italic/NNP Mountains/NNPS)\n",
      "  ,/,\n",
      "  she/PRP\n",
      "  had/VBD\n",
      "  a/DT\n",
      "  last/JJ\n",
      "  view/NN\n",
      "  back/RB\n",
      "  on/IN\n",
      "  the/DT\n",
      "  skyline/NN\n",
      "  of/IN\n",
      "  her/PRP$\n",
      "  hometown/JJ\n",
      "  Bookmarksgrove/NNP\n",
      "  ,/,\n",
      "  the/DT\n",
      "  headline/NN\n",
      "  of/IN\n",
      "  (ORGANIZATION Alphabet/NNP Village/NNP)\n",
      "  and/CC\n",
      "  the/DT\n",
      "  subline/NN\n",
      "  of/IN\n",
      "  her/PRP$\n",
      "  own/JJ\n",
      "  road/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (ORGANIZATION Line/NNP Lane/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "entities = nltk.ne_chunk(speech_char)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-jerusalem",
   "metadata": {},
   "source": [
    "## h) Find all words in your text that end with _ed_, _ing_ or _s_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "healthy-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mountains\n",
      "countries\n",
      "texts\n",
      "Separated\n",
      "Semantics\n",
      "named\n",
      "flows\n",
      "supplies\n",
      "is\n",
      "roasted\n",
      "parts\n",
      "sentences\n",
      "Pointing\n",
      "has\n",
      "texts\n",
      "is\n",
      "decided\n",
      "advised\n",
      "thousands\n",
      "Commas\n",
      "Marks\n",
      "devious\n",
      "packed\n",
      "reached\n",
      "hills\n",
      "Mountains\n"
     ]
    }
   ],
   "source": [
    "for word in tokens:\n",
    "    if re.search(r'(ed|ing|s)$', word):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-spring",
   "metadata": {},
   "source": [
    "## i) Save output of one of the above functions to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distinct-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab5output.txt', 'w') as f:\n",
    "    f.write(str(entities))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
